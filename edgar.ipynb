{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/cik_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803.0</td>\n",
       "      <td>3/6/1998</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805.0</td>\n",
       "      <td>5/15/1998</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808.0</td>\n",
       "      <td>8/13/1998</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811.0</td>\n",
       "      <td>11/12/1998</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811.0</td>\n",
       "      <td>11/16/1998</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CIK            CONAME     FYRMO       FDATE     FORM  \\\n",
       "0  3662.0  SUNBEAM CORP/FL/  199803.0    3/6/1998  10-K405   \n",
       "1  3662.0  SUNBEAM CORP/FL/  199805.0   5/15/1998     10-Q   \n",
       "2  3662.0  SUNBEAM CORP/FL/  199808.0   8/13/1998  NT 10-Q   \n",
       "3  3662.0  SUNBEAM CORP/FL/  199811.0  11/12/1998   10-K/A   \n",
       "4  3662.0  SUNBEAM CORP/FL/  199811.0  11/16/1998  NT 10-Q   \n",
       "\n",
       "                                   SECFNAME  \n",
       "0  edgar/data/3662/0000950170-98-000413.txt  \n",
       "1  edgar/data/3662/0000950170-98-001001.txt  \n",
       "2  edgar/data/3662/0000950172-98-000783.txt  \n",
       "3  edgar/data/3662/0000950170-98-002145.txt  \n",
       "4  edgar/data/3662/0000950172-98-001203.txt  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some blank rows. Need to delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis='index', how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 152 records and 6 columns initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803.0</td>\n",
       "      <td>3/6/1998</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805.0</td>\n",
       "      <td>5/15/1998</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808.0</td>\n",
       "      <td>8/13/1998</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811.0</td>\n",
       "      <td>11/12/1998</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811.0</td>\n",
       "      <td>11/16/1998</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CIK            CONAME     FYRMO       FDATE     FORM  \\\n",
       "0  3662.0  SUNBEAM CORP/FL/  199803.0    3/6/1998  10-K405   \n",
       "1  3662.0  SUNBEAM CORP/FL/  199805.0   5/15/1998     10-Q   \n",
       "2  3662.0  SUNBEAM CORP/FL/  199808.0   8/13/1998  NT 10-Q   \n",
       "3  3662.0  SUNBEAM CORP/FL/  199811.0  11/12/1998   10-K/A   \n",
       "4  3662.0  SUNBEAM CORP/FL/  199811.0  11/16/1998  NT 10-Q   \n",
       "\n",
       "                                   SECFNAME  \n",
       "0  edgar/data/3662/0000950170-98-000413.txt  \n",
       "1  edgar/data/3662/0000950170-98-001001.txt  \n",
       "2  edgar/data/3662/0000950172-98-000783.txt  \n",
       "3  edgar/data/3662/0000950170-98-002145.txt  \n",
       "4  edgar/data/3662/0000950172-98-001203.txt  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A utility method to get a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    page = requests.get(url)\n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A utility method to get a soup object using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(page):\n",
    "    return BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL to the report repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.sec.gov/Archives/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate this common urlwith individual resources as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-000413.txt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url + df.iloc[0][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will traverse each row of the DataFrame, fetch the resource at the concatenated url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new DataFrame for variables only. We will later merge it with the original DataFrame to append records for individual rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variables = pd.DataFrame(columns=['mda_positive_score', 'mda_negative_score', 'mda_polarity_score', 'mda_average_sentence_length'\n",
    "                                    'mda_percentage_of_complex_words', 'mda_fog_index', 'mda_complex_word_count', 'mda_word_count',\n",
    "                                    'mda_uncertainty_score', 'mda_constraining_score', 'mda_positive_word_proportion', 'mda_negative_word_proportion',\n",
    "                                    'mda_uncertainty_word_proportion', 'mda_constraining_word_proportion', 'qqdmr_positive_score', 'qqdmr_negative_score',\n",
    "                                    'qqdmr_polarity_score', 'qqdmr_average_sentence_length', 'qqdmr_percentage_of_complex_words', 'qqdmr_fog_index',\n",
    "                                    'qqdmr_complex_word_count', 'qqdmr_word_count', 'qqdmr_uncertainty_score', 'qqdmr_constraining_score', 'qqdmr_positive_word_proportion',\n",
    "                                    'qqdmr_negative_word_proportion', 'qqdmr_uncertainty_word_proportion', 'qqdmr_constraining_word_proportion', 'rf_positive_score',\n",
    "                                    'rf_negative_score', 'rf_polarity_score', 'rf_average_sentence_length', 'rf_percentage_of_complex_words', 'rf_fog_index',\n",
    "                                    'rf_complex_word_count', 'rf_word_count', 'rf_uncertainty_score', 'rf_constraining_score', 'rf_positive_word_proportion',\n",
    "                                    'rf_negative_word_proportion', 'rf_uncertainty_word_proportion', 'rf_constraining_word_proportion', 'constraining_words_whole_report'\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mda_positive_score</th>\n",
       "      <th>mda_negative_score</th>\n",
       "      <th>mda_polarity_score</th>\n",
       "      <th>mda_average_sentence_lengthmda_percentage_of_complex_words</th>\n",
       "      <th>mda_fog_index</th>\n",
       "      <th>mda_complex_word_count</th>\n",
       "      <th>mda_word_count</th>\n",
       "      <th>mda_uncertainty_score</th>\n",
       "      <th>mda_constraining_score</th>\n",
       "      <th>mda_positive_word_proportion</th>\n",
       "      <th>...</th>\n",
       "      <th>rf_fog_index</th>\n",
       "      <th>rf_complex_word_count</th>\n",
       "      <th>rf_word_count</th>\n",
       "      <th>rf_uncertainty_score</th>\n",
       "      <th>rf_constraining_score</th>\n",
       "      <th>rf_positive_word_proportion</th>\n",
       "      <th>rf_negative_word_proportion</th>\n",
       "      <th>rf_uncertainty_word_proportion</th>\n",
       "      <th>rf_constraining_word_proportion</th>\n",
       "      <th>constraining_words_whole_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [mda_positive_score, mda_negative_score, mda_polarity_score, mda_average_sentence_lengthmda_percentage_of_complex_words, mda_fog_index, mda_complex_word_count, mda_word_count, mda_uncertainty_score, mda_constraining_score, mda_positive_word_proportion, mda_negative_word_proportion, mda_uncertainty_word_proportion, mda_constraining_word_proportion, qqdmr_positive_score, qqdmr_negative_score, qqdmr_polarity_score, qqdmr_average_sentence_length, qqdmr_percentage_of_complex_words, qqdmr_fog_index, qqdmr_complex_word_count, qqdmr_word_count, qqdmr_uncertainty_score, qqdmr_constraining_score, qqdmr_positive_word_proportion, qqdmr_negative_word_proportion, qqdmr_uncertainty_word_proportion, qqdmr_constraining_word_proportion, rf_positive_score, rf_negative_score, rf_polarity_score, rf_average_sentence_length, rf_percentage_of_complex_words, rf_fog_index, rf_complex_word_count, rf_word_count, rf_uncertainty_score, rf_constraining_score, rf_positive_word_proportion, rf_negative_word_proportion, rf_uncertainty_word_proportion, rf_constraining_word_proportion, constraining_words_whole_report]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 42 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Loughran McDonald Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loughran_mcdonald = pd.read_csv('dataset/LoughranMcDonald_MasterDictionary_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Sequence Number</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Word Proportion</th>\n",
       "      <th>Average Proportion</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Doc Count</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Constraining</th>\n",
       "      <th>Superfluous</th>\n",
       "      <th>Interesting</th>\n",
       "      <th>Modal</th>\n",
       "      <th>Irr_Verb</th>\n",
       "      <th>Harvard_IV</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARDVARK</td>\n",
       "      <td>1</td>\n",
       "      <td>277</td>\n",
       "      <td>1.480000e-08</td>\n",
       "      <td>1.240000e-08</td>\n",
       "      <td>3.560000e-06</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AARDVARKS</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.600000e-10</td>\n",
       "      <td>9.730000e-12</td>\n",
       "      <td>9.860000e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABACI</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4.280000e-10</td>\n",
       "      <td>1.390000e-10</td>\n",
       "      <td>6.230000e-08</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABACK</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>6.410000e-10</td>\n",
       "      <td>3.160000e-10</td>\n",
       "      <td>9.380000e-08</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABACUS</td>\n",
       "      <td>5</td>\n",
       "      <td>7250</td>\n",
       "      <td>3.870000e-07</td>\n",
       "      <td>3.680000e-07</td>\n",
       "      <td>3.370000e-05</td>\n",
       "      <td>914</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Sequence Number  Word Count  Word Proportion  \\\n",
       "0   AARDVARK                1         277     1.480000e-08   \n",
       "1  AARDVARKS                2           3     1.600000e-10   \n",
       "2      ABACI                3           8     4.280000e-10   \n",
       "3      ABACK                4          12     6.410000e-10   \n",
       "4     ABACUS                5        7250     3.870000e-07   \n",
       "\n",
       "   Average Proportion       Std Dev  Doc Count  Negative  Positive  \\\n",
       "0        1.240000e-08  3.560000e-06         84         0         0   \n",
       "1        9.730000e-12  9.860000e-09          1         0         0   \n",
       "2        1.390000e-10  6.230000e-08          7         0         0   \n",
       "3        3.160000e-10  9.380000e-08         12         0         0   \n",
       "4        3.680000e-07  3.370000e-05        914         0         0   \n",
       "\n",
       "   Uncertainty  Litigious  Constraining  Superfluous  Interesting  Modal  \\\n",
       "0            0          0             0            0            0      0   \n",
       "1            0          0             0            0            0      0   \n",
       "2            0          0             0            0            0      0   \n",
       "3            0          0             0            0            0      0   \n",
       "4            0          0             0            0            0      0   \n",
       "\n",
       "   Irr_Verb  Harvard_IV  Syllables     Source  \n",
       "0         0           0          2  12of12inf  \n",
       "1         0           0          2  12of12inf  \n",
       "2         0           0          3  12of12inf  \n",
       "3         0           0          2  12of12inf  \n",
       "4         0           0          3  12of12inf  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loughran_mcdonald.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Constraining Words Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraining_dictionary = pd.read_csv('dataset/constraining_dictionary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Uncertainty Words Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_dictionary = pd.read_csv('dataset/uncertainty_dictionary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create three utility methods for extracting three sections in a particular document. The sections are:\n",
    "1. \"Management's Discussion and Analysis\": mda()\n",
    "2. \"Quantitative and Qualitative Disclosures about Market Risk\": qqdmr()\n",
    "3. \"Risk Factors\": rf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetVariables():\n",
    "    \n",
    "    def __init__(self, page, mda, qqdmr, rf):\n",
    "        self.page = page\n",
    "        self.mda = mda\n",
    "        self.qqdmr = qqdmr\n",
    "        self.rf = rf\n",
    "        \n",
    "    def remove_punctuation(self):\n",
    "        return ''.join([char for char in self.text if char not in punctuation])\n",
    "        \n",
    "    def tokenize(self):\n",
    "        return word_tokenize(self.text)\n",
    "    \n",
    "    def remove_stop_words(self):\n",
    "        after_stop_words_removal = [word for word in self.tokenize(word) if word not in stopwords.words('english')]\n",
    "        \n",
    "    def preprocess(self):\n",
    "        self.text = self.remove_punctuation()\n",
    "        self.text = self.remove_stop_words()\n",
    "        return self.text\n",
    "    \n",
    "    def mda(self):\n",
    "        desired_string = re.split(\".\\s{0,2}MANAGEMENT'S DISCUSSION AND ANALYSIS\", self.page, re.IGNORECASE)\n",
    "        if desired_string[0] == self.page:\n",
    "            return None\n",
    "        desired_string = re.split(\"ITEM \\d\", desired_string[-1], re.IGNORECASE)[0]\n",
    "        desired_string = re.split(\"OF OPERATIONS?\", desired_string, re.IGNORECASE)\n",
    "        self.mda = desired_string[-1]\n",
    "    \n",
    "    def qqdmr(self):\n",
    "        desired_string = re.split(\".\\s{0,2}QUANTITATIVE AND QUALITATIVE\", self.page, re.IGNORECASE)\n",
    "        if desired_string[0] == page:\n",
    "            return None\n",
    "        desired_string = re.split(\"ITEM\", desired_string[-1], re.IGNORECASE)[0]\n",
    "        desired_string = re.split(\"ABOUT MARKET RISK\", desired_string, re.IGNORECASE)\n",
    "        self.qqdmr desired_string[-1]\n",
    "        \n",
    "    def rf(self):\n",
    "        desired_string = re.split(\".\\s{0,2} RISK FACTORS\", self.page, re.IGNORECASE)\n",
    "        if desired_string[0] == page:\n",
    "            return None\n",
    "        print(desired_string)\n",
    "        desired_string = re.split(\"ITEM \\d\", desired_string[-1], re.IGNORECASE)[0]\n",
    "        self.rf = desired_string\n",
    "        \n",
    "    def word_count(self, section):\n",
    "        return section.split(' ')\n",
    "        \n",
    "    def sentence_count(self, section):\n",
    "        return section.split('. ')\n",
    "    \n",
    "    def complex_word_count(self, section):\n",
    "        sentence_list = self.num_of_sentences(section)\n",
    "        complex_word_count = 0\n",
    "        for word in sentence_list:\n",
    "            if word[-2:] == 'es':\n",
    "                complex_word_count -= 1 \n",
    "            if word[-2:] == 'ed':\n",
    "                complex_word_count -= 1\n",
    "            for char in word:\n",
    "                if char in 'aeiou':\n",
    "                    complex_word_count += 1\n",
    "        return complex_word_count\n",
    "    \n",
    "    def positive_score(self, section):\n",
    "        positive_score = 0\n",
    "        word_list = self.word_count(section)\n",
    "        for word in word_list:\n",
    "            if not loughran_mcdonald[loughran_mcdonald['Word'] == word]['Positive'].empty:\n",
    "                positive_score += 1\n",
    "        return positive_score\n",
    "        \n",
    "    def negative_score(self, section):\n",
    "        negative_score = 0\n",
    "        word_list = section.split()\n",
    "        for word in word_list:\n",
    "            if not loughran_mcdonald[loughran_mcdonald['Word'] == word]['Negative'].empty:\n",
    "                negative_score += 1\n",
    "        return negative_score\n",
    "        \n",
    "    def polarity_score(self, positive_score, negative_score):\n",
    "        return (positive_score – negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "        \n",
    "    def average_sentence_length(self, section):\n",
    "        return self.word_count(section) / self.sentence_count(section)\n",
    "        \n",
    "    def percentage_of_complex_words(self, section):\n",
    "        self.complex_word_count(section) / self.word_count(section)\n",
    "        \n",
    "    def fog_index(self, section):\n",
    "        return 0.4 * (self.average_sentence_length(section) + self.percentage_of_complex_words(section))\n",
    "        \n",
    "    def uncertainty_score(self, section):\n",
    "        uncertainty_score = 0\n",
    "        word_list = self.word_count(section)\n",
    "        for word in word_list:\n",
    "            if word in uncertainty_dictionary.values:\n",
    "                uncertainty_score += 1\n",
    "        return uncertainty_score\n",
    "        \n",
    "    def constraining_score(self, section):\n",
    "        constraining_score = 0\n",
    "        word_list = self.word_count(section)\n",
    "        for word in word_list:\n",
    "            if word in constraining_dictionary.values:\n",
    "                constraining_score += 1\n",
    "        return constraining_score\n",
    "        \n",
    "    def positive_word_proportion(self, positive_score, word_count):\n",
    "        return positive_score / word_count\n",
    "        \n",
    "    def negative_word_proportion(self, negative_score, word_count):\n",
    "        return positive_score / word_count        \n",
    "        \n",
    "    def uncertainty_word_proportion(self, uncertainty_score, word_count):\n",
    "        return uncertainty_score / word_count\n",
    "        \n",
    "    def constraining_word_proportion(self, constraining_score, word_count):\n",
    "        return constraining_score / word_count    \n",
    "         \n",
    "    def constraining_words_whole_report(self, page):\n",
    "        constraining_words_whole_report = 0\n",
    "        word_list = self.word_count(page)\n",
    "        for word in word_list:\n",
    "            if word in constraining_dictionary.values:\n",
    "                constraining_words_whole_report += 1\n",
    "        return constraining_words_whole_report \n",
    "    \n",
    "    def get_variables():\n",
    "        \n",
    "        # Invoking methods for MDA and storing values in variables serving as DataFrame Columns.\n",
    "        mda_positive_score = self.positive_score(self.page, 'mda')\n",
    "        self.list.append(mda_positive_score)\n",
    "        self.list.append(self.negative_score(self.page, 'mda'))\n",
    "        self.list.append(self.polarity_score(self.page, 'mda'))\n",
    "        self.list.append(self.average_sentence_length(self.page, 'mda'))\n",
    "        self.list.append(self.percentage_of_complex_words(self.page, 'mda'))\n",
    "        self.list.append(self.fog_index(self.page, 'mda'))\n",
    "        self.list.append(self.complex_word_count(self.page, 'mda'))\n",
    "        mda_word_count = self.word_count(self.page, 'mda')\n",
    "        self.list.append(mda_word_count)\n",
    "        self.list.append(self.uncertainty_score(self.page, 'mda'))\n",
    "        self.list.append(self.constraining_score(self.page, 'mda'))   \n",
    "        self.list.append(self.positive_word_proportion(self.page, mda_positive_score, mda_word_count))\n",
    "        mda_negative_score = self.negative_score(self.page, 'mda')\n",
    "        self.list.append(self.negative_word_proportion(self.page, mda_negative_score, mda_word_count))\n",
    "        mda_uncertainty_score = self.uncertainty_score(self.page, 'mda')\n",
    "        self.list.append(self.uncertainty_word_proportion(self.page, mda_uncertainty_score, mda_word_count))\n",
    "        mda_constraining_score = self.constraining_score(self.page, 'mda')\n",
    "        self.list.append(self.constraining_word_proportion(self.page, mda_constraining_score, mda_word_count))\n",
    "        \n",
    "        # Invoking methods for QQDMR and storing values in variables serving as DataFrame Columns.\n",
    "        qqdmr_positive_score = self.positive_score(self.page, 'qqdmr')\n",
    "        self.list.append(qqdmr_positive_score)\n",
    "        self.list.append(self.negative_score(self.page, 'qqdmr'))\n",
    "        self.list.append(self.polarity_score(self.page, 'qqdmr'))\n",
    "        self.list.append(self.average_sentence_length(self.page, 'qqdmr'))\n",
    "        self.list.append(self.percentage_of_complex_words(self.page, 'qqdmr'))\n",
    "        self.list.append(self.fog_index(self.page, 'qqdmr'))\n",
    "        self.list.append(self.complex_word_count(self.page, 'qqdmr'))\n",
    "        qqdmr_word_count = self.word_count(self.page, 'qqdmr')\n",
    "        self.list.append(qqdmr_word_count)\n",
    "        self.list.append(self.uncertainty_score(self.page, 'qqdmr'))\n",
    "        self.list.append(self.constraining_score(self.page, 'qqdmr'))   \n",
    "        self.list.append(self.positive_word_proportion(self.page, qqdmr_positive_score, qqdmr_word_count))\n",
    "        qqdmr_negative_score = self.negative_score(self.page, 'qqdmr')\n",
    "        self.list.append(self.negative_word_proportion(self.page, qqdmr_negative_score, qqdmr_word_count))\n",
    "        qqdmr_uncertainty_score = self.uncertainty_score(self.page, 'qqdmr')\n",
    "        self.list.append(self.uncertainty_word_proportion(self.page, qqdmr_uncertainty_score, qqdmr_word_count))\n",
    "        qqdmr_constraining_score = self.constraining_score(self.page, 'qqdmr')\n",
    "        self.list.append(self.constraining_word_proportion(self.page, qqdmr_constraining_score, qqdmr_word_count))\n",
    "        \n",
    "        # Invoking methods for RF and storing values in variables serving as DataFrame Columns.\n",
    "        mda_positive_score = self.positive_score(self.page, 'rf')\n",
    "        self.list.append(rf_positive_score)\n",
    "        self.list.append(self.negative_score(self.page, 'rf'))\n",
    "        self.list.append(self.polarity_score(self.page, 'rf'))\n",
    "        self.list.append(self.average_sentence_length(self.page, 'rf'))\n",
    "        self.list.append(self.percentage_of_complex_words(self.page, 'rf'))\n",
    "        self.list.append(self.fog_index(self.page, 'rf'))\n",
    "        self.list.append(self.complex_word_count(self.page, 'rf'))\n",
    "        rf_word_count = self.word_count(self.page, 'rf')\n",
    "        self.list.append(rf_word_count)\n",
    "        self.list.append(self.uncertainty_score(self.page, 'rf'))\n",
    "        self.list.append(self.constraining_score(self.page, 'rf'))   \n",
    "        self.list.append(self.positive_word_proportion(self.page, rf_positive_score, rf_word_count))\n",
    "        rf_negative_score = self.negative_score(self.page, 'rf')\n",
    "        self.list.append(self.negative_word_proportion(self.page, rf_negative_score, rf_word_count))\n",
    "        rf_uncertainty_score = self.uncertainty_score(self.page, 'rf')\n",
    "        self.list.append(self.uncertainty_word_proportion(self.page, rf_uncertainty_score, rf_word_count))\n",
    "        rf_constraining_score = self.constraining_score(self.page, 'rf')\n",
    "        self.list.append(self.constraining_word_proportion(self.page, rf_constraining_score, rf_word_count))\n",
    "        self.list.append(self.constraining_words_whole_report(self.page))\n",
    "        \n",
    "        # Returning a list of variables serving as DataFrame Columns.\n",
    "        return self.list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we visit each url, store its content in an HTML file 'document.html', use methods in the class 'GetVariables' to\n",
    "extract out sections and for each section, get the metrics, save them to a list of variables. Finally we append that list\n",
    "to a new DataFrame 'df_variables' and eventually merge it to original DataFrame 'df' which only consisted of Company Details originally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.iterrows():\n",
    "    # Fetch a URL\n",
    "    page = get_page('https://www.sec.gov/Archives/' + df.loc[i][-1])\n",
    "    # The fetched URL is unparsed HTML. Need to store it in an HTML file, then visit the new URL, and apply soup to it.\n",
    "    write_document = open('document.html', 'wb').write(page.content)\n",
    "    page = open('document.html', 'r').read()\n",
    "    df_variables.loc[len(df_variables)] = GetVariables(page).get_variables()\n",
    "df = pd.concat([df, df_variables], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
